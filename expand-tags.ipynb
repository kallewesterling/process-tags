{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import json\n",
    "import csv\n",
    "import tweepy\n",
    "import yaml\n",
    "\n",
    "from pathlib import Path\n",
    "from time import sleep\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up cache directories\n",
    "tweet_cache_dir = Path('./__cache__/tweets/')\n",
    "user_cache_dir = Path('./__cache__/users/')\n",
    "\n",
    "if not tweet_cache_dir.is_dir(): tweet_cache_dir.mkdir(parents=True)\n",
    "if not user_cache_dir.is_dir(): user_cache_dir.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up tweepy\n",
    "class _TwitterCredentials():\n",
    "\n",
    "    def __init__(self):\n",
    "        with open('../conference-documentation/credentials.yml') as f: self._ = yaml.load(f)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self._[i]\n",
    "\n",
    "twitter_credentials = _TwitterCredentials()\n",
    "\n",
    "auth = tweepy.OAuthHandler(twitter_credentials['consumer_key'], twitter_credentials['consumer_secret'])\n",
    "auth.set_access_token(twitter_credentials['access_token'], twitter_credentials['access_token_secret'])\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_tags_tsv(file):\n",
    "    if Path(file).is_file(): _ = [Path(file)]\n",
    "    elif Path(file).is_dir(): _ = Path(file).glob(pattern=\"*.tsv\")\n",
    "    else:\n",
    "        raise RuntimeError(f\"Cannot interpret passed argument: {file}\")\n",
    "    for file in _:\n",
    "        with Path(file).open(\"r\") as f:\n",
    "            _len = len(f.readlines())\n",
    "        with Path(file).open(\"r\") as f:\n",
    "            bar = progressbar.ProgressBar(max_value=_len).start()\n",
    "            reader = csv.DictReader(f, delimiter='\\t')\n",
    "            for i, rows in enumerate(reader):\n",
    "                bar.update(i)\n",
    "                _dict = tags_to_dict(rows)\n",
    "                \n",
    "                tweet_cache = tweet_cache_dir / _dict[\"id_str\"]\n",
    "                if not tweet_cache.is_file():\n",
    "                    ## First, check twitter for tweet here... \n",
    "                    try:\n",
    "                        live_tweet = api.get_status(_dict['id_str'], tweet_mode=\"extended\")\n",
    "                        _json = live_tweet._json\n",
    "                        _json['json_source'] = 'Twitter'\n",
    "\n",
    "                        _json_user = _json['user']\n",
    "                        _json['user'] = _json_user['id']\n",
    "\n",
    "                        with Path(tweet_cache).open(\"w+\") as f:\n",
    "                            json.dump(_json, f)\n",
    "\n",
    "                        user_cache = user_cache_dir / str(_json_user[\"id\"])\n",
    "                        if not user_cache.is_file():\n",
    "                            with Path(user_cache).open(\"w+\") as f:\n",
    "                                _json_user['json_source'] = 'Twitter'\n",
    "                                json.dump(_json_user, f)\n",
    "                    \n",
    "                    except tweepy.TweepError as e:\n",
    "                        ## No tweet available:\n",
    "                        with Path(tweet_cache).open(\"w+\") as f:\n",
    "                            _dict['error'] = str(e)\n",
    "                            json.dump(_dict, f)\n",
    "                        try:\n",
    "                            user_cache = user_cache_dir / str(_dict[\"user\"][\"id_str\"])\n",
    "                            if not user_cache.is_file():\n",
    "                                live_user = api.get_user(_dict[\"user\"][\"id_str\"])\n",
    "                                _json_user = live_user._json\n",
    "                                \n",
    "                                # remove the user's latest status\n",
    "                                try: del _json_user['status']\n",
    "                                except KeyError: pass\n",
    "                                \n",
    "                                _json_user['json_source'] = 'Twitter'\n",
    "                                \n",
    "                                with Path(user_cache).open(\"w+\") as f:\n",
    "                                    json.dump(_json_user, f)\n",
    "                                    \n",
    "                        except tweepy.TweepError as e:\n",
    "                            if not user_cache.is_file():\n",
    "                                _json_user = {\"error\": str(e)}\n",
    "                                with Path(user_cache).open(\"w+\") as f:\n",
    "                                    json.dump(_json_user, f)\n",
    "                    \n",
    "            bar.finish()\n",
    "\n",
    "def tags_to_dict(rows):\n",
    "    if not rows['id_str']:\n",
    "        print(\"STOP\")\n",
    "    \n",
    "    _dict = {\n",
    "        'created_at': rows['created_at'],\n",
    "        'id': int(rows['id_str']),\n",
    "        'id_str': rows['id_str'],\n",
    "                        'from_user': rows['from_user'],\n",
    "        'full_text': rows['text'],\n",
    "        'geo_coordinates': rows['geo_coordinates'],\n",
    "        'lang': rows['user_lang'],\n",
    "        'in_reply_to_user_id_str': rows['in_reply_to_user_id_str'],\n",
    "        'in_reply_to_screen_name': rows['in_reply_to_screen_name'],\n",
    "        'user': {\n",
    "            'id_str': rows['from_user_id_str'],\n",
    "            'followers_count': rows['user_followers_count'],\n",
    "            'friends_count': rows['user_friends_count'],\n",
    "        },\n",
    "        'in_reply_to_status_id_str': rows['in_reply_to_status_id_str'],\n",
    "        'source': rows['source'],\n",
    "        'profile_image_url': rows['profile_image_url'],\n",
    "        'entities_str': rows['entities_str'],\n",
    "        'json_source': \"TAGS\"\n",
    "    }\n",
    "    return(_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% (832 of 26167) |                    | Elapsed Time: 0:01:27 ETA:   1:42:35"
     ]
    }
   ],
   "source": [
    "# The expand_tags_tsv function accepts whole directories or, if you prefer, individual TAGS archive sheets, saved as .tsv files\n",
    "expand_tags_tsv('../../datasets/tags-tsv/male striptease/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
