{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import json\n",
    "import csv\n",
    "import tweepy\n",
    "import yaml\n",
    "\n",
    "from pathlib import Path\n",
    "from time import sleep\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up cache directories\n",
    "tweet_cache_dir = Path('./__cache__/tweets/')\n",
    "user_cache_dir = Path('./__cache__/users/')\n",
    "\n",
    "if not tweet_cache_dir.is_dir(): tweet_cache_dir.mkdir(parents=True)\n",
    "if not user_cache_dir.is_dir(): user_cache_dir.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up tweepy\n",
    "class _TwitterCredentials():\n",
    "\n",
    "    def __init__(self):\n",
    "        with open('../conference-documentation/credentials.yml') as f: self._ = yaml.load(f)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self._[i]\n",
    "\n",
    "twitter_credentials = _TwitterCredentials()\n",
    "\n",
    "auth = tweepy.OAuthHandler(twitter_credentials['consumer_key'], twitter_credentials['consumer_secret'])\n",
    "auth.set_access_token(twitter_credentials['access_token'], twitter_credentials['access_token_secret'])\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_tags_tsv(file):\n",
    "    if Path(file).is_file(): _ = [Path(file)]\n",
    "    elif Path(file).is_dir(): _ = Path(file).glob(pattern=\"*.tsv\")\n",
    "    else:\n",
    "        raise RuntimeError(f\"Cannot interpret passed argument: {file}\")\n",
    "    for file in _:\n",
    "        with Path(file).open(\"r\") as f:\n",
    "            _len = len(f.readlines())\n",
    "        with Path(file).open(\"r\") as f:\n",
    "            bar = progressbar.ProgressBar(max_value=_len).start()\n",
    "            reader = csv.DictReader(f, delimiter='\\t')\n",
    "            for i, rows in enumerate(reader):\n",
    "                bar.update(i)\n",
    "                if not rows['created_at'] and not rows['from_user'] and not rows['text']:\n",
    "                    pass\n",
    "                else:\n",
    "                    _dict = tags_to_dict(rows)\n",
    "                \n",
    "                    tweet_cache = tweet_cache_dir / _dict[\"id_str\"]\n",
    "                    if not tweet_cache.is_file():\n",
    "                        ## First, check twitter for tweet here... \n",
    "                        try:\n",
    "                            live_tweet = api.get_status(_dict['id_str'], tweet_mode=\"extended\")\n",
    "                            _json = live_tweet._json\n",
    "                            _json['json_source'] = 'Twitter'\n",
    "\n",
    "                            _json_user = _json['user']\n",
    "                            _json['user'] = _json_user['id']\n",
    "\n",
    "                            with Path(tweet_cache).open(\"w+\") as f:\n",
    "                                json.dump(_json, f)\n",
    "\n",
    "                            user_cache = user_cache_dir / str(_json_user[\"id\"])\n",
    "                            if not user_cache.is_file():\n",
    "                                with Path(user_cache).open(\"w+\") as f:\n",
    "                                    _json_user['json_source'] = 'Twitter'\n",
    "                                    json.dump(_json_user, f)\n",
    "\n",
    "                        except tweepy.TweepError as e:\n",
    "                            ## No tweet available:\n",
    "                            with Path(tweet_cache).open(\"w+\") as f:\n",
    "                                _dict['error'] = str(e)\n",
    "                                json.dump(_dict, f)\n",
    "                            try:\n",
    "                                user_cache = user_cache_dir / str(_dict[\"user\"][\"id_str\"])\n",
    "                                if not user_cache.is_file():\n",
    "                                    live_user = api.get_user(_dict[\"user\"][\"id_str\"])\n",
    "                                    _json_user = live_user._json\n",
    "\n",
    "                                    # remove the user's latest status\n",
    "                                    try: del _json_user['status']\n",
    "                                    except KeyError: pass\n",
    "\n",
    "                                    _json_user['json_source'] = 'Twitter'\n",
    "\n",
    "                                    with Path(user_cache).open(\"w+\") as f:\n",
    "                                        json.dump(_json_user, f)\n",
    "\n",
    "                            except tweepy.TweepError as e:\n",
    "                                if not user_cache.is_file():\n",
    "                                    _json_user = {\"error\": str(e)}\n",
    "                                    with Path(user_cache).open(\"w+\") as f:\n",
    "                                        json.dump(_json_user, f)\n",
    "\n",
    "            bar.finish()\n",
    "\n",
    "def tags_to_dict(rows):\n",
    "    if not rows['id_str']:\n",
    "        print(\"STOP\")\n",
    "        pprint(rows)\n",
    "        exit()\n",
    "    else:\n",
    "        _dict = {\n",
    "            'created_at': rows['created_at'],\n",
    "            'id': int(rows['id_str']),\n",
    "            'id_str': rows['id_str'],\n",
    "                            'from_user': rows['from_user'],\n",
    "            'full_text': rows['text'],\n",
    "            'geo_coordinates': rows['geo_coordinates'],\n",
    "            'lang': rows['user_lang'],\n",
    "            'in_reply_to_user_id_str': rows['in_reply_to_user_id_str'],\n",
    "            'in_reply_to_screen_name': rows['in_reply_to_screen_name'],\n",
    "            'user': {\n",
    "                'id_str': rows['from_user_id_str'],\n",
    "                'followers_count': rows['user_followers_count'],\n",
    "                'friends_count': rows['user_friends_count'],\n",
    "            },\n",
    "            'in_reply_to_status_id_str': rows['in_reply_to_status_id_str'],\n",
    "            'source': rows['source'],\n",
    "            'profile_image_url': rows['profile_image_url'],\n",
    "            'entities_str': rows['entities_str'],\n",
    "            'json_source': \"TAGS\"\n",
    "        }\n",
    "    return(_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39% (10211 of 26167) |#######           | Elapsed Time: 0:04:46 ETA:   0:58:50Rate limit reached. Sleeping for: 614\n",
      " 43% (11344 of 26167) |#######           | Elapsed Time: 0:20:11 ETA:   1:10:04Rate limit reached. Sleeping for: 594\n",
      " 47% (12488 of 26167) |########          | Elapsed Time: 0:35:29 ETA:   2:04:08Rate limit reached. Sleeping for: 580\n",
      " 51% (13602 of 26167) |#########         | Elapsed Time: 0:50:39 ETA:   0:56:32Rate limit reached. Sleeping for: 576\n",
      " 56% (14724 of 26167) |##########        | Elapsed Time: 1:05:43 ETA:   0:51:18Rate limit reached. Sleeping for: 577\n"
     ]
    }
   ],
   "source": [
    "# The expand_tags_tsv function accepts whole directories or, if you prefer, individual TAGS archive sheets, saved as .tsv files\n",
    "expand_tags_tsv('../../datasets/tags-tsv/male striptease/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_tags_tsv('../../datasets/tags-tsv/boy-lesque/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_tags_tsv('../../datasets/tags-tsv/male burlesque/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
