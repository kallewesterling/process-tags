{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'TAGS' has no attribute 'TweetSet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-40348c888897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"../../datasets/tags-tsv/boylesque/TAGS - boylesque - Archive.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuppress_warnings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTweetSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuppress_warnings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'full_text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"boylesque\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_retweets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'TAGS' has no attribute 'TweetSet'"
     ]
    }
   ],
   "source": [
    "tags = TAGS.Document(path=\"../../datasets/tags-tsv/boylesque/TAGS - boylesque - Archive.tsv\", suppress_warnings=True)\n",
    "ids = tags.ids\n",
    "tweets = TAGS.TweetSet(ids, suppress_warnings=True, progressbar=False, filter_key='full_text', filter_value=\"boylesque\", include_retweets=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[957183619386179584,\n",
       " 923051501399965696,\n",
       " 982681455909273600,\n",
       " 853943528912715777,\n",
       " 837996413460021248,\n",
       " 858807036829630464,\n",
       " 1125792856709398534,\n",
       " 1123995654747979782,\n",
       " 820247487713640448,\n",
       " 829977424716759040]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up standard variables\n",
    "errors, all_data, all_errors = 0, [], []\n",
    "slices = tweets.tweets[0:200]\n",
    "\n",
    "with open('./configuration/block_list.txt', 'r') as f:\n",
    "    block_list = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 (1 remaining) - errors: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "for i, tweet in enumerate(slices):\n",
    "    clean_text = CleanText(tweet.full_text)\n",
    "    clear_output(wait=True)\n",
    "    print(f\"{i}/{len(slices)} ({len(slices)-i} remaining) - errors: {errors}\")\n",
    "    print(\"\\n- \".join(all_errors))\n",
    "    inferred = False\n",
    "    lat, lng, boundingbox, geolocator = None, None, None, None\n",
    "\n",
    "    # Geolocation\n",
    "    if tweet.geo:\n",
    "        lat = tweet.geo['coordinates'][0]\n",
    "        lng = tweet.geo['coordinates'][1]\n",
    "        inferred = False\n",
    "        geolocator = None\n",
    "    elif tweet.user.location is not None: # and only_roman_chars(tweet.user.location)\n",
    "        try:\n",
    "            location = Location(\n",
    "                tweet.user.location, \n",
    "                block=block_list, \n",
    "                replacements_yaml = \"./configuration/location_mapping.yml\"\n",
    "            )\n",
    "        except GeocoderTimedOut:\n",
    "            location = None\n",
    "            errors += 1\n",
    "            cleaner = CleanText.CleanText(tweet.user.location)\n",
    "            cleaner.digits = False\n",
    "            cleaner.clean()\n",
    "            all_errors.append(f\"{i}: {cleaner.text}\")\n",
    "            if errors == 10: raise RuntimeError(\"Too many errors.\") from None\n",
    "        if location is not None and not location.error:\n",
    "            if location.data is not None:\n",
    "                lat = location.data.get('lat', None)\n",
    "                lng = location.data.get('lng', None)\n",
    "                boundingbox = location.data.get('boundingbox', None)\n",
    "                inferred = True\n",
    "                geolocator = location.geolocator\n",
    "    elif tweet.user.location is not None and not only_roman_chars(tweet.user.location):\n",
    "        pass # or:\n",
    "                # print(f\"Location contained non-roman characters: {tweet.user.location}\")\n",
    "    data = {\n",
    "        'clean_text': clean_text,\n",
    "        'boundingbox': boundingbox,\n",
    "        'lat': lat,\n",
    "        'lng': lng,\n",
    "        'inferred': inferred,\n",
    "        'date': time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(tweet.created_at,'%a %b %d %H:%M:%S +0000 %Y')),\n",
    "        'lang': tweet.lang,\n",
    "        'geolocator': geolocator,\n",
    "        'full_text': tweet.full_text\n",
    "    }\n",
    "    all_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>boundingbox</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>inferred</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>geolocator</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video game burlesque thurs march feat striptea...</td>\n",
       "      <td>[51.7657055, 51.9771532, 0.6993788, 1.0268034]</td>\n",
       "      <td>51.8896903</td>\n",
       "      <td>0.8994651</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-27 09:28:53</td>\n",
       "      <td>en</td>\n",
       "      <td>Nominatim</td>\n",
       "      <td>Video Game Burlesque! Thurs 29th March @TheBir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>macho rock preening faggotry collide part boyl...</td>\n",
       "      <td>[33.7036216, 34.337306, -118.6681776, -118.155...</td>\n",
       "      <td>34.0536909</td>\n",
       "      <td>-118.2427666</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-25 05:00:02</td>\n",
       "      <td>en</td>\n",
       "      <td>Nominatim</td>\n",
       "      <td>Macho ‘80s rock and preening faggotry collide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>award winning international boylesque stars br...</td>\n",
       "      <td>None</td>\n",
       "      <td>39.7481</td>\n",
       "      <td>-104.996</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-04-07 18:08:11</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>Award-winning international boylesque stars br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>back year</td>\n",
       "      <td>[49.674, 61.061, -14.015517, 2.0919117]</td>\n",
       "      <td>54.7023545</td>\n",
       "      <td>-3.2765753</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-03-04 12:01:28</td>\n",
       "      <td>en</td>\n",
       "      <td>Nominatim</td>\n",
       "      <td>Back for a 2nd year! #bhof #bhof17 #lousafire ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mixing lineup dynamic dance boylesque punky my...</td>\n",
       "      <td>[42.3730513, 42.4181407, -71.1345919, -71.0734...</td>\n",
       "      <td>42.3875968</td>\n",
       "      <td>-71.0994968</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-05-07 16:01:47</td>\n",
       "      <td>en</td>\n",
       "      <td>Nominatim</td>\n",
       "      <td>Mixing up the lineup with dynamic dance and bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>check stonewall inn rt hobby fun evening stone...</td>\n",
       "      <td>[40.477399, 40.9161785, -74.25909, -73.7001809]</td>\n",
       "      <td>40.7127281</td>\n",
       "      <td>-74.0060152</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-03-12 02:59:55</td>\n",
       "      <td>en</td>\n",
       "      <td>Nominatim</td>\n",
       "      <td>Check out Stonewall Inn: https://t.co/ACtUtlRe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>world boylesque photo credit mo pitz hidden wo...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-05-29 18:58:03</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>The World of “Boylesque”: \\nPhoto Credit: Mo P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>man walks metal bar wearing hat know not afrai...</td>\n",
       "      <td>[30.0984576, 30.5166255, -97.9367663, -97.5605...</td>\n",
       "      <td>30.2711286</td>\n",
       "      <td>-97.7436995</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-07-28 01:25:27</td>\n",
       "      <td>en</td>\n",
       "      <td>Nominatim</td>\n",
       "      <td>Man walks into a metal bar wearing that hat, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td></td>\n",
       "      <td>[50.0099945, 50.0899945, 10.193302, 10.273302]</td>\n",
       "      <td>50.0499945</td>\n",
       "      <td>10.233302</td>\n",
       "      <td>True</td>\n",
       "      <td>2015-12-31 08:07:58</td>\n",
       "      <td>und</td>\n",
       "      <td>Nominatim</td>\n",
       "      <td>#maizucker #berlin #burlesque #bbf2015 #burles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>decided pull custom piece made amazing made ba...</td>\n",
       "      <td>[49.1984452, 49.3161714, -123.2249611, -123.02...</td>\n",
       "      <td>49.2608724</td>\n",
       "      <td>-123.1139529</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-03-03 09:12:14</td>\n",
       "      <td>en</td>\n",
       "      <td>Nominatim</td>\n",
       "      <td>Decided to pull out my custom piece made for m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            clean_text  \\\n",
       "0    video game burlesque thurs march feat striptea...   \n",
       "1    macho rock preening faggotry collide part boyl...   \n",
       "2    award winning international boylesque stars br...   \n",
       "3                                            back year   \n",
       "4    mixing lineup dynamic dance boylesque punky my...   \n",
       "..                                                 ...   \n",
       "195  check stonewall inn rt hobby fun evening stone...   \n",
       "196  world boylesque photo credit mo pitz hidden wo...   \n",
       "197  man walks metal bar wearing hat know not afrai...   \n",
       "198                                                      \n",
       "199  decided pull custom piece made amazing made ba...   \n",
       "\n",
       "                                           boundingbox         lat  \\\n",
       "0       [51.7657055, 51.9771532, 0.6993788, 1.0268034]  51.8896903   \n",
       "1    [33.7036216, 34.337306, -118.6681776, -118.155...  34.0536909   \n",
       "2                                                 None     39.7481   \n",
       "3              [49.674, 61.061, -14.015517, 2.0919117]  54.7023545   \n",
       "4    [42.3730513, 42.4181407, -71.1345919, -71.0734...  42.3875968   \n",
       "..                                                 ...         ...   \n",
       "195    [40.477399, 40.9161785, -74.25909, -73.7001809]  40.7127281   \n",
       "196                                               None        None   \n",
       "197  [30.0984576, 30.5166255, -97.9367663, -97.5605...  30.2711286   \n",
       "198     [50.0099945, 50.0899945, 10.193302, 10.273302]  50.0499945   \n",
       "199  [49.1984452, 49.3161714, -123.2249611, -123.02...  49.2608724   \n",
       "\n",
       "              lng  inferred                 date lang geolocator  \\\n",
       "0       0.8994651      True  2018-01-27 09:28:53   en  Nominatim   \n",
       "1    -118.2427666      True  2017-10-25 05:00:02   en  Nominatim   \n",
       "2        -104.996     False  2018-04-07 18:08:11   en       None   \n",
       "3      -3.2765753      True  2017-03-04 12:01:28   en  Nominatim   \n",
       "4     -71.0994968      True  2019-05-07 16:01:47   en  Nominatim   \n",
       "..            ...       ...                  ...  ...        ...   \n",
       "195   -74.0060152      True  2017-03-12 02:59:55   en  Nominatim   \n",
       "196          None     False  2015-05-29 18:58:03   en       None   \n",
       "197   -97.7436995      True  2019-07-28 01:25:27   en  Nominatim   \n",
       "198     10.233302      True  2015-12-31 08:07:58  und  Nominatim   \n",
       "199  -123.1139529      True  2019-03-03 09:12:14   en  Nominatim   \n",
       "\n",
       "                                             full_text  \n",
       "0    Video Game Burlesque! Thurs 29th March @TheBir...  \n",
       "1    Macho ‘80s rock and preening faggotry collide ...  \n",
       "2    Award-winning international boylesque stars br...  \n",
       "3    Back for a 2nd year! #bhof #bhof17 #lousafire ...  \n",
       "4    Mixing up the lineup with dynamic dance and bo...  \n",
       "..                                                 ...  \n",
       "195  Check out Stonewall Inn: https://t.co/ACtUtlRe...  \n",
       "196  The World of “Boylesque”: \\nPhoto Credit: Mo P...  \n",
       "197  Man walks into a metal bar wearing that hat, y...  \n",
       "198  #maizucker #berlin #burlesque #bbf2015 #burles...  \n",
       "199  Decided to pull out my custom piece made for m...  \n",
       "\n",
       "[200 rows x 9 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clean_text': check stonewall inn rt hobby fun evening stonewall,\n",
       " 'boundingbox': ['40.477399', '40.9161785', '-74.25909', '-73.7001809'],\n",
       " 'lat': '40.7127281',\n",
       " 'lng': '-74.0060152',\n",
       " 'inferred': True,\n",
       " 'date': '2017-03-12 02:59:55',\n",
       " 'lang': 'en',\n",
       " 'geolocator': 'Nominatim',\n",
       " 'full_text': 'Check out Stonewall Inn: https://t.co/ACtUtlRegs - RT @BryanKnight66 Hobby to the #nyceagle after a fun #boylesque evening @ Stonewall In...'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[195]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from shapely.geometry import Point\n",
    "from shapely.geometry import box\n",
    "\n",
    "point = Point(0.5, 0.5)\n",
    "b = box(-75.7854388,-75.6325211,4.3951997,4.5895768)\n",
    "print(b.contains(point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(-75.7854388, -75.6325211),\n",
    "(4.3951997, 4.5895768),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "locations/colchester.json Colchester, Essex, East of England, England, United Kingdom\n",
      "(min_lng,max_lng,min_lat,max_lat)\n",
      "(0.6993788,1.0268034,51.7657055,51.9771532)\n",
      "51.8896903 0.8994651\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bounding box is: \"south Latitude, north Latitude, west Longitude, east Longitude\"\n",
    "# according to https://wiki.openstreetmap.org/wiki/Bounding_Box\n",
    "for file in Path('./locations/').glob('colchester.json'):\n",
    "    with file.open() as f:\n",
    "        data = json.load(f)\n",
    "        if data['boundingbox'] is not None:\n",
    "            min_lat = data['boundingbox'][0]\n",
    "            max_lat = data['boundingbox'][1]\n",
    "            min_lng = data['boundingbox'][2]\n",
    "            max_lng = data['boundingbox'][3]\n",
    "            print(file, data['display_name'])\n",
    "            print(f\"(min_lng,max_lng,min_lat,max_lat)\")\n",
    "            print(f\"({min_lng},{max_lng},{min_lat},{max_lat})\")\n",
    "            print(data['lat'], data['lng'])\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundingbox(location = None):\n",
    "    if not location: raise RuntimeError(f\"Location must be set to not None.\")\n",
    "    location = clean_location(tweet.user.location)\n",
    "    if len(location):\n",
    "        cache_file = location_cache_directory / Path(location + \".json\")\n",
    "        if cache_file.is_file():\n",
    "            geo_data = read_cache(cache_file)\n",
    "            return_data = geo_data.get('boundingbox', None)\n",
    "            if isinstance(return_data, list): \n",
    "                print(\"return_data is a list!\")\n",
    "                return_data = [float(x) for x in return_data] # returned as list of floats: [NS/latitude min, NS/latitude max; EW/longitude min; EW/longitude max]\n",
    "            return(return_data)\n",
    "        else:\n",
    "            log(f\"Cannot read cache file / file does not exist: {cache_file}\")\n",
    "            return(None)\n",
    "\n",
    "def get_user_location(tweet):\n",
    "    if tweet.user.location is not None:\n",
    "        location = clean_location(tweet.user.location)\n",
    "    else:\n",
    "        return(False)\n",
    "    \n",
    "    if not location or len(location) == 0 or not only_roman_chars(location): # for now, this is the implementation\n",
    "        return(False)\n",
    "    else:\n",
    "        cache_file = location_cache_directory / Path(location + \".json\")\n",
    "        if cache_file.is_file():\n",
    "            geo_data = read_cache(cache_file)\n",
    "            lat = geo_data.get('lat', None)\n",
    "            lng = geo_data.get('lng', None)\n",
    "            if lat: lat = float(lat)\n",
    "            if lng: lat = float(lng)\n",
    "            return([lat, lng])\n",
    "        else:\n",
    "            log(f\"Cannot read cache file / file does not exist: {cache_file}\", 1)\n",
    "            return(False)\n",
    "\n",
    "def get_native_tweet_location(tweet):\n",
    "    if tweet.geo is not None and tweet.geo.get('coordinates', None):\n",
    "        coordinates = tweet.geo.get('coordinates', None)\n",
    "        if coordinates: coordinates = [float(x) for x in coordinates]\n",
    "        return(coordinates)\n",
    "    else:\n",
    "        return(False)\n",
    "\n",
    "def return_keywords_in_bounding_box(tweets, location = None, boundingbox = [], include_inferred = True, filter = True):\n",
    "    all_keywords, total_processed_tweets = {}, 0\n",
    "    if not location and not boundingbox: raise RuntimeError(\"Location or boundingbox must be provided.\")\n",
    "    if location and boundingbox: raise RuntimeError(\"Location or boundingbox must be provided, not both.\")\n",
    "\n",
    "    # We have been provided with location, let's extract boundingbox\n",
    "    if location: boundingbox = get_boundingbox(location = location)\n",
    "        \n",
    "    # We have been provided with boundingbox, let's make sure datatypes are correct\n",
    "    if boundingbox and isinstance(boundingbox, list): boundingbox = [float(x) for x in boundingbox]\n",
    "    \n",
    "    if filter:\n",
    "        total_unfiltered_tweets = len(tweets)\n",
    "        log(f\"Filtering {total_unfiltered_tweets} tweets.\", 1)\n",
    "        tweets = [x for x in tweets \n",
    "                      if not TAGS.clean_text(x.full_text).startswith(\"rt\") \n",
    "                      and \"boylesque\" in TAGS.clean_text(x.full_text)\n",
    "                 ]\n",
    "        total_num_tweets = len(tweets)\n",
    "        log(f\"=> {total_num_tweets} filtered tweets.\", 1)\n",
    "    \n",
    "    bar = progressbar.ProgressBar(maxval=total_num_tweets).start()\n",
    "    for i, tweet in enumerate(tweets):\n",
    "        clear_output()\n",
    "        bar.update(i)\n",
    "        if get_native_tweet_location(tweet):\n",
    "            lat, lng = get_native_tweet_location(tweet)[0], get_native_tweet_location(tweet)[1]\n",
    "        elif include_inferred and get_user_location(tweet):\n",
    "            lat, lng = get_user_location(tweet)[0], get_user_location(tweet)[1]\n",
    "        else:\n",
    "            lat, lng = None, None\n",
    "\n",
    "        # check if lat + lng + boundingbox exists\n",
    "        if lat and lng and boundingbox:\n",
    "            # TODO: test for type not float....!\n",
    "            if (boundingbox[1] > lat > boundingbox[0]) and (boundingbox[3] > lng > boundingbox[2]):\n",
    "                full_text = tweet.full_text.replace(\"amp\", \"\")\n",
    "                keywords = TAGS.clean_text(full_text)\n",
    "\n",
    "                for keyword in keywords.split(\" \"):\n",
    "                    if keyword not in all_keywords: all_keywords[keyword] = 0\n",
    "                    all_keywords[keyword] += 1\n",
    "                total_processed_tweets += 1\n",
    "    bar.finish()\n",
    "\n",
    "    return({'total_unfiltered_tweets': total_unfiltered_tweets, 'total_num_tweets': total_num_tweets, 'total_processed_tweets': total_processed_tweets, 'all_keywords': all_keywords})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-656-a31ce161dcab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# return_keywords_in_bounding_box(tweets.tweets, boundingbox=['24.76' ,'49.21', '-128.232422', '-66.88']) # = retrieves all keywords from the U.S... not very precise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# return_keywords_in_bounding_box(tweets.tweets, boundingbox=['31', '49.21', '-128', '-116']) # = retrieves keywords from the west coast of U.S.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mreturn_keywords_in_bounding_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboundingbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'25'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'49.21'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-81'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-66.5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# = retrieves keywords from the east coast of U.S.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-655-e782ed13c50d>\u001b[0m in \u001b[0;36mreturn_keywords_in_bounding_box\u001b[0;34m(tweets, location, boundingbox, include_inferred, filter)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# check if lat + lng + boundingbox exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlng\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mboundingbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mboundingbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlat\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mboundingbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mboundingbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlng\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mboundingbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0mfull_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"amp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "# return_keywords_in_bounding_box(tweets.tweets, location = \"colchester\") # retrieve all the keywords from colchester..\n",
    "# return_keywords_in_bounding_box(tweets.tweets, location='Austin, TX') # = retrieves all keywords from Austin, TX\n",
    "# you can also use include_inferred parameter to exclude those tweets where location is inferred through the user's fill-in location [although I am not sure that works just yet]\n",
    "\n",
    "# [min_lat, max_lat, min_lng, max_lng]\n",
    "# A couple of boundingboxes:\n",
    "#  - UK: ['51.765706', '59.645540', '-11.601563', '1.026803']\n",
    "#  - US: ['24.76' ,'49.21', '-128.232422', '-66.88']\n",
    "#       east coast: ['25', '49.21', '-81', '-66.5']\n",
    "#       west coast: ['31', '49.21', '-128', '-116']\n",
    "\n",
    "\n",
    "# Example: Get all keywords from tweets from UK: return_keywords_in_bounding_box(tweets.tweets, boundingbox=['51.765706', '59.645540', '-11.601563', '1.026803'])\n",
    "# return_keywords_in_bounding_box(tweets.tweets, boundingbox=['51.765706' ,'59.645540', '-128.232422', '1.026803'])\n",
    "\n",
    "# return_keywords_in_bounding_box(tweets.tweets, boundingbox=['24.76' ,'49.21', '-128.232422', '-66.88']) # = retrieves all keywords from the U.S... not very precise\n",
    "# return_keywords_in_bounding_box(tweets.tweets, boundingbox=['31', '49.21', '-128', '-116']) # = retrieves keywords from the west coast of U.S. \n",
    "return_keywords_in_bounding_box(tweets.tweets, boundingbox=['25', '49.21', '-81', '-66.5']) # = retrieves keywords from the east coast of U.S. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
